{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wizard339/education/blob/main/misis/nlp/text_classification/transfer_learning_nlp_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4QrD0qmKkiRL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import torch\n",
        "import torchtext\n",
        "import gensim.downloader\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.types import Device\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from prompt_toolkit import output\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data, EDA, data preprocessing"
      ],
      "metadata": {
        "id": "pSRRIo1JlDyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data"
      ],
      "metadata": {
        "id": "zASd3CbiAtx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data = pd.read_csv(filepath_or_buffer='https://raw.githubusercontent.com/wizard339/education/main/misis/nlp/text_classification/train.csv', index_col=0)\n",
        "final_test_raw_data = pd.read_csv(filepath_or_buffer='https://raw.githubusercontent.com/wizard339/education/main/misis/nlp/text_classification/test.csv')\n",
        "\n",
        "print(f'Shape of train: {train_raw_data.shape}')\n",
        "print(f'Shape of test: {final_test_raw_data.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI6DAnfpk7rv",
        "outputId": "8cfdbf0d-f038-41ca-9473-44fc9d145d6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train: (41159, 2)\n",
            "Shape of test: (3798, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with missing data"
      ],
      "metadata": {
        "id": "JWrgde2Lucb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the data:\n"
      ],
      "metadata": {
        "id": "RUiEV9aau6qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1sa0Mvfzlx1Z",
        "outputId": "b76462fb-3cba-4f34-81e5-1d527a4ec477"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text           Sentiment\n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral\n",
              "1  advice Talk to your neighbours family to excha...            Positive\n",
              "2  Coronavirus Australia: Woolworths to give elde...            Positive\n",
              "3  My food stock is not the only one which is emp...            Positive\n",
              "4  Me, ready to go at supermarket during the #COV...  Extremely Negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb761ec2-5ee6-4320-b2a5-cf0ebc63e293\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb761ec2-5ee6-4320-b2a5-cf0ebc63e293')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb761ec2-5ee6-4320-b2a5-cf0ebc63e293 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb761ec2-5ee6-4320-b2a5-cf0ebc63e293');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEOVFQHdmsiE",
        "outputId": "96565bf9-2533-4859-cce4-5761f604f6e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 41159 entries, 0 to 41156\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Text       41158 non-null  object\n",
            " 1   Sentiment  41155 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 964.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are rows with missing data. Let's look at them:"
      ],
      "metadata": {
        "id": "0_CvsTtvvN2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data[train_raw_data['Sentiment'].isnull() == True]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZUENGV0Hpwzj",
        "outputId": "c1b11485-b9fe-4762-8226-0985c593047d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      Text Sentiment\n",
              "33122    @PrivyCouncilCA #SocialDistancing isnÂt enoug...       NaN\n",
              "NaN                                                Neutral       NaN\n",
              "39204    @TanDhesi @foreignoffice @Afzal4Gorton @Expres...       NaN\n",
              "Neutral                                                NaN       NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77275a40-d142-48c0-8dea-b0e4076ca266\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33122</th>\n",
              "      <td>@PrivyCouncilCA #SocialDistancing isnÂt enoug...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39204</th>\n",
              "      <td>@TanDhesi @foreignoffice @Afzal4Gorton @Expres...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neutral</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77275a40-d142-48c0-8dea-b0e4076ca266')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77275a40-d142-48c0-8dea-b0e4076ca266 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77275a40-d142-48c0-8dea-b0e4076ca266');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's drop these rows from our DataFrame because they don't carry much value and let's look at the data again:"
      ],
      "metadata": {
        "id": "AdeIHPFjv-Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data = train_raw_data.dropna().reset_index(drop=True)\n",
        "print(f'New shape of train: {train_raw_data.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_S2wW1Ov52V",
        "outputId": "c6bb0417-f400-4ab6-8f72-9ae9f9be0f1b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of train: (41155, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ysjsa6gw-hr",
        "outputId": "2a582917-ca72-4b29-90c6-7dae84f52c5e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 41155 entries, 0 to 41154\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Text       41155 non-null  object\n",
            " 1   Sentiment  41155 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 643.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the lines of texts:"
      ],
      "metadata": {
        "id": "C4C_C1RIidNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([len(text.split()) for text in train_raw_data['Text']])"
      ],
      "metadata": {
        "id": "lFX68FAAiUEF",
        "outputId": "94d1c14b-c980-4f71-9f16-191ea035f600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 530., 3268., 4924., 6560., 6257., 7495., 8516., 3053.,  529.,\n",
              "          23.]),\n",
              " array([ 1. ,  7.3, 13.6, 19.9, 26.2, 32.5, 38.8, 45.1, 51.4, 57.7, 64. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([len(text.split()) for text in final_test_raw_data['Text']])"
      ],
      "metadata": {
        "id": "LEfqHImMiRqL",
        "outputId": "c7882f87-5a6d-4437-9462-f7797e0a84e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 24., 231., 356., 477., 543., 623., 701., 629., 199.,  15.]),\n",
              " array([ 2.,  8., 14., 20., 26., 32., 38., 44., 50., 56., 62.]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no sequences that are too long and the distributions in the training and test samples are similar. It is good."
      ],
      "metadata": {
        "id": "gR7OO311irog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label encoding of target column"
      ],
      "metadata": {
        "id": "qR5dBpDmBOto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data['Sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7zW7Diayv0I",
        "outputId": "b0705e76-9595-4ca5-80cc-77cfb4ebfe36"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive              11422\n",
              "Negative               9917\n",
              "Neutral                7711\n",
              "Extremely Positive     6624\n",
              "Extremely Negative     5481\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(train_raw_data['Sentiment'])\n",
        "train_raw_data['Sentiment'] = le.transform(train_raw_data['Sentiment'])\n",
        "train_raw_data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8CVn5RlO9H1D",
        "outputId": "d081f6e6-976e-4ad3-ef75-a95127aadc15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text  Sentiment\n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...          3\n",
              "1  advice Talk to your neighbours family to excha...          4\n",
              "2  Coronavirus Australia: Woolworths to give elde...          4\n",
              "3  My food stock is not the only one which is emp...          4\n",
              "4  Me, ready to go at supermarket during the #COV...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e38e6a75-f929-4e59-8f89-4f00377fbb2b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e38e6a75-f929-4e59-8f89-4f00377fbb2b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e38e6a75-f929-4e59-8f89-4f00377fbb2b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e38e6a75-f929-4e59-8f89-4f00377fbb2b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сleaning text from useless data"
      ],
      "metadata": {
        "id": "0AMv6PmTBj8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the text more closely:"
      ],
      "metadata": {
        "id": "lrE0m0XYCMO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data['Text'].sample(10, random_state=42).values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONquVuGj-YRd",
        "outputId": "ae5ed3e8-4009-4810-8b7c-6d4e7c3284c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['So panic buying of soaps and toilet roll was bad enough, now the idiots are stockpiling alcohol ? whats wrong with people #CoronaVirus #StopPanicBuying #Covid_19',\n",
              "       'I would place a large amount of money this is the guy buying 90 of the toilet paper',\n",
              "       '\"Saudi Arabia is bracing for an economic downturn as oil prices plummet due to the #coronavirus pandemic\" https://t.co/PQ3eRX9euZ',\n",
              "       '#Foodsecurity #coronavirus #covid19 \\r\\r\\n1.Smooth flow of global trade will help secure food supply\\r\\r\\n2.Monitoring food prices and markets\\r\\r\\n3.Sharing relevant information transparently\\r\\r\\n4.Supporting the vulnerable countries and populationsÂ\\x85https://t.co/tTPmInVVgS https://t.co/Ums3Eueu6J',\n",
              "       'I d like to know who is stockpiling eggs cheese and ice cream and why I m used to going without as our local Lidl has been running out of all kinds of stuff for years way before Drives me potty Going to the supermarket is like entering a lottery',\n",
              "       'Whenever you touch any object or surface outside your abode #washyourhands with #soapandwater\\r\\r\\n\\r\\r\\n#staysafe #stayhome\\r\\r\\n#sanitizer #socialdistancing \\r\\r\\n#covid19 #sd\\r\\r\\n#coronavirus \\r\\r\\n#chinesevirus\\r\\r\\n#asiegercares \\r\\r\\n#who #asieger https://t.co/UYM6i83PeP',\n",
              "       'P.S.A for those buying ?. The human body can survive upwards of 40 days with no food. Water is the most important thing during these times; especially since you canÂ\\x92t go more then 3 days without it before death. Think wise and not in a panic induced state. Stay safe. #Covid_19',\n",
              "       'Publix. Walmart. Thats how its spreading through our community. You may stay home all week, then go get a gallon of milk with a side of Covid-19Why would you set limits of boats in the waters to stay 50ft apart, But not regulate the amount of people in a supermarket.#coronavirus',\n",
              "       'Our healthcare community is the backbone of the response to #Coronavirus. @marty_walsh is committed to supporting them, so certain garages in the @CityOfBoston are now offering reduced prices for hospital staff. \\r\\r\\n\\r\\r\\nhttps://t.co/VFpW5FXObJ',\n",
              "       'Lilliesleaf clapped as Alan played for  NHS workers, delivery people, supermarket staff, carers and everyone out there taking care of the sick and keeping the country going. You have to squint to see the people at their houses but they are there. #clapforkeyworkers #coronavirus https://t.co/VqIZSCKCvE'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaner(text: str) -> str:\n",
        "    '''will clean from unicode, url, hashtags, numbers,\n",
        "    nicknames, lower'''\n",
        "    # text = re.sub(r'[.,#!$%\\^&\\*;:{}=\\-_`~()]',r'',text) # punct.\n",
        "    \n",
        "    # text = re.sub(r'(\\\\u[0-9A-Fa-f]+)',r'', text)       \n",
        "    text = re.sub(r'[^\\x00-\\x7f]', r'', text)# unicode\n",
        "\n",
        "    # text = re.sub(r'\\\\[a-z]', r'', text)\n",
        "    \n",
        "    text = re.sub(r'http\\S+', r'', text)# url\n",
        "    \n",
        "    text = re.sub('@[A-Za-z0-9_-]+', r'', text)# nickname\n",
        "    \n",
        "    text = re.sub(r'#([^\\s]+)', r'\\1', text)# hashtag symbol\n",
        "    \n",
        "    text = re.sub(':\\)|;\\)|:-\\)|\\(-:|:-D|=D|:P|xD|X-p|\\^\\^|:-*|\\^\\.\\^|\\^\\-\\^|\\^\\_\\^|\\,-\\)|\\)-:|:\\'\\(|:\\(|:-\\(|:\\S|T\\.T|\\.\\_\\.|:<|:-\\S|:-<|\\*\\-\\*|:O|=O|=\\-O|O\\.o|XO|O\\_O|:-\\@|=/|:/|X\\-\\(|>\\.<|>=\\(|D:',\n",
        "                  '', text) # emoji\n",
        "    \n",
        "    text = ''.join([i for i in text if not i.isdigit()])# int.\n",
        "    \n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "VljsoMJbB_qy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data['Text'] = train_raw_data['Text'].apply(text_cleaner)\n",
        "final_test_raw_data['Text'] = final_test_raw_data['Text'].apply(text_cleaner)\n",
        "train_raw_data['Text'].sample(10, random_state=42).values"
      ],
      "metadata": {
        "id": "UYTDnZvKSFoF",
        "outputId": "81f66677-fe2a-4598-dcf5-523f94aa66aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['so panic buying of soaps and toilet roll was bad enough, now the idiots are stockpiling alcohol ? whats wrong with people coronavirus stoppanicbuying covid_',\n",
              "       'i would place a large amount of money this is the guy buying  of the toilet paper',\n",
              "       '\"saudi arabia is bracing for an economic downturn as oil prices plummet due to the coronavirus pandemic\" ',\n",
              "       'foodsecurity coronavirus covid \\r\\r\\n.smooth flow of global trade will help secure food supply\\r\\r\\n.monitoring food prices and markets\\r\\r\\n.sharing relevant information transparently\\r\\r\\n.supporting the vulnerable countries and populations ',\n",
              "       'i d like to know who is stockpiling eggs cheese and ice cream and why i m used to going without as our local lidl has been running out of all kinds of stuff for years way before drives me potty going to the supermarket is like entering a lottery',\n",
              "       'whenever you touch any object or surface outside your abode washyourhands with soapandwater\\r\\r\\n\\r\\r\\nstaysafe stayhome\\r\\r\\nsanitizer socialdistancing \\r\\r\\ncovid sd\\r\\r\\ncoronavirus \\r\\r\\nchinesevirus\\r\\r\\nasiegercares \\r\\r\\nwho asieger ',\n",
              "       'p.s.a for those buying ?. the human body can survive upwards of  days with no food. water is the most important thing during these times; especially since you cant go more then  days without it before death. think wise and not in a panic induced state. stay safe. covid_',\n",
              "       'publix. walmart. thats how its spreading through our community. you may stay home all week, then go get a gallon of milk with a side of covid-why would you set limits of boats in the waters to stay ft apart, but not regulate the amount of people in a supermarket.coronavirus',\n",
              "       'our healthcare community is the backbone of the response to coronavirus.  is committed to supporting them, so certain garages in the  are now offering reduced prices for hospital staff. \\r\\r\\n\\r\\r\\n',\n",
              "       'lilliesleaf clapped as alan played for  nhs workers, delivery people, supermarket staff, carers and everyone out there taking care of the sick and keeping the country going. you have to squint to see the people at their houses but they are there. clapforkeyworkers coronavirus '],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization"
      ],
      "metadata": {
        "id": "7tWDMRnGjanh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def build_vocabulary(datasets):\n",
        "  for dataset in datasets:\n",
        "    for text in dataset['Text']:\n",
        "      yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(build_vocabulary([train_raw_data, final_test_raw_data]), specials=['<UNK>'])\n",
        "vocab.set_default_index(vocab['<UNK>'])"
      ],
      "metadata": {
        "id": "88kvuR7RjZpC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Vocabulary length: {vocab.__len__()}')"
      ],
      "metadata": {
        "id": "OrnCeVg1s-8S",
        "outputId": "fecd7162-8607-4557-bfb3-52649b3c83a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary length: 50653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting of training data"
      ],
      "metadata": {
        "id": "ThzzFC5jXcAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to split our train_raw_data by train, validation and test samples in the proportions of 60:20:20.\n",
        "\n",
        "However, our data contain texts for 5 classes, so it is necessary to keep stratification after their splitting."
      ],
      "metadata": {
        "id": "dZenBWDaYCyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first, we will split data by two samples: train and test in the proportion of 60:40\n",
        "train_data, test_data = train_test_split(train_raw_data, test_size=0.2, stratify=train_raw_data['Sentiment'], random_state=42)\n",
        "# then, we will split test data by two samples: validation and test in the proportion of 50:50 \n",
        "val_data, test_data = train_test_split(test_data, test_size=0.5, stratify=test_data['Sentiment'], random_state=42)"
      ],
      "metadata": {
        "id": "S7oQ4XouXB2O"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the stratification:"
      ],
      "metadata": {
        "id": "I8GaEeMceLD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data['Sentiment'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "qqZHawm1cWVX",
        "outputId": "95619817-0672-42f6-b85b-15447d5c7055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    0.277536\n",
              "2    0.240967\n",
              "3    0.187365\n",
              "1    0.160952\n",
              "0    0.133179\n",
              "Name: Sentiment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Sentiment'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "zyY-tnNOb7Op",
        "outputId": "dc9ed2c0-478e-434d-eb09-8ed9401a7890",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    0.277518\n",
              "2    0.240979\n",
              "3    0.187371\n",
              "1    0.160946\n",
              "0    0.133186\n",
              "Name: Sentiment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data['Sentiment'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "sH7m85vfcD5T",
        "outputId": "d0b06f8d-b3ff-49db-ef8d-0944658ba5bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    0.277521\n",
              "2    0.240826\n",
              "3    0.187363\n",
              "1    0.161118\n",
              "0    0.133171\n",
              "Name: Sentiment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['Sentiment'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "JbB208eCcuG4",
        "outputId": "fc0fe44f-5b94-4217-8f7d-56e77c28d1c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    0.277697\n",
              "2    0.241011\n",
              "3    0.187318\n",
              "1    0.160836\n",
              "0    0.133139\n",
              "Name: Sentiment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of the train_data: {train_data.shape}')\n",
        "print(f'Shape of the val_data: {val_data.shape}')\n",
        "print(f'Shape of the test_data: {test_data.shape}')\n",
        "print(f'Shape of the finel_test_raw_data: {final_test_raw_data.shape}')"
      ],
      "metadata": {
        "id": "4vxoU9e5cvtM",
        "outputId": "d5c10274-64f8-4128-e63b-8e23cfa36a62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the train_data: (32924, 2)\n",
            "Shape of the val_data: (4115, 2)\n",
            "Shape of the test_data: (4116, 2)\n",
            "Shape of the finel_test_raw_data: (3798, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating datasets"
      ],
      "metadata": {
        "id": "shBQrhdpuQuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset, test_dataset, final_test_dataset = to_map_style_dataset(train_data.values), \\\n",
        "                                                               to_map_style_dataset(val_data.values), \\\n",
        "                                                               to_map_style_dataset(test_data.values), \\\n",
        "                                                               to_map_style_dataset(final_test_raw_data.values)\n",
        "\n",
        "MAX_WORDS  = 60\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "def vectorize_batch(batch):\n",
        "  X, Y = list(zip(*batch))\n",
        "  X = [vocab(tokenizer(text)) for text in X] # tokenize and map tokens to indexes\n",
        "  X = [tokens+([0]*(MAX_WORDS - len(tokens))) if len(tokens) < MAX_WORDS else tokens[:MAX_WORDS] for tokens in X]\n",
        "  return torch.tensor(X, dtype=torch.int32, device='cpu'), torch.tensor(Y, device='cpu')\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=vectorize_batch, shuffle=True)\n",
        "val_loader  = DataLoader(val_dataset , batch_size=BATCH_SIZE, collate_fn=vectorize_batch, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset , batch_size=BATCH_SIZE, collate_fn=vectorize_batch, shuffle=True)\n",
        "final_test_loader  = DataLoader(final_test_dataset , batch_size=BATCH_SIZE, collate_fn=vectorize_batch)"
      ],
      "metadata": {
        "id": "ELlMKrurtkwT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prompt_toolkit import output\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "EMBED_LEN  = 50\n",
        "HIDDEN_DIM = 75\n",
        "N_LAYERS   = 1\n",
        "\n",
        "target_classes = train_raw_data['Sentiment'].unique()\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTMClassifier, self).__init__()\n",
        "    self.emb_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=EMBED_LEN)\n",
        "    self.lstm = nn.LSTM(input_size=EMBED_LEN, hidden_size=HIDDEN_DIM, num_layers=N_LAYERS, batch_first=True)\n",
        "    self.fc = nn.Linear(in_features=HIDDEN_DIM, out_features=len(target_classes))\n",
        "    # self.drop = nn.Dropout(p=0.5)\n",
        "    \n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    emb = self.emb_layer(X_batch)\n",
        "    output, (h, c) = self.lstm(emb)\n",
        "    # output = self.drop(output)\n",
        "    return self.fc(output[:, -1])"
      ],
      "metadata": {
        "id": "t5DND2Taxizj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_classifier = LSTMClassifier()\n",
        "\n",
        "lstm_classifier"
      ],
      "metadata": {
        "id": "puqO8pktxsMR",
        "outputId": "37ac12b8-1ae7-4441-b4a9-9e3271b07a1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMClassifier(\n",
              "  (emb_layer): Embedding(50653, 50)\n",
              "  (lstm): LSTM(50, 75, batch_first=True)\n",
              "  (fc): Linear(in_features=75, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in lstm_classifier.children():\n",
        "  print(f'Layer: {layer}')\n",
        "  print('Parameters: ')\n",
        "  for param in layer.parameters():\n",
        "    print(param.shape)\n",
        "  print()"
      ],
      "metadata": {
        "id": "2mPUE5vLx9Qm",
        "outputId": "11a9c221-8c2d-4594-f88a-9cd4ce7e8809",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: Embedding(50653, 50)\n",
            "Parameters: \n",
            "torch.Size([50653, 50])\n",
            "\n",
            "Layer: LSTM(50, 75, batch_first=True)\n",
            "Parameters: \n",
            "torch.Size([300, 50])\n",
            "torch.Size([300, 75])\n",
            "torch.Size([300])\n",
            "torch.Size([300])\n",
            "\n",
            "Layer: Linear(in_features=75, out_features=5, bias=True)\n",
            "Parameters: \n",
            "torch.Size([5, 75])\n",
            "torch.Size([5])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n",
        "  with torch.no_grad():\n",
        "    Y_shuffled, Y_preds, losses = [], [], []\n",
        "    for X, Y in val_loader:\n",
        "      preds = model(X)\n",
        "      loss = loss_fn(preds, Y)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      Y_shuffled.append(Y)\n",
        "      Y_preds.append(preds.argmax(dim=-1))\n",
        "\n",
        "    Y_shuffled = torch.cat(Y_shuffled)\n",
        "    Y_preds = torch.cat(Y_preds)\n",
        "\n",
        "    print(f'Valid Loss: {torch.tensor(losses).cpu().mean():.3f}')\n",
        "    print(f'Valid Acc : {accuracy_score(Y_shuffled.cpu().detach().numpy(), Y_preds.cpu().detach().numpy()):.3f}')\n",
        "\n",
        "\n",
        "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, device, epochs=10):\n",
        "\n",
        "  for i in range(1, epochs+1):\n",
        "    losses = []\n",
        "    for X, Y in tqdm(train_loader):\n",
        "      X.to(device)\n",
        "      Y.to(device)\n",
        "      model.to(device)\n",
        "\n",
        "      Y_preds = model(X)\n",
        "\n",
        "      loss = loss_fn(Y_preds, Y)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    print(f'Train Loss: {torch.tensor(losses).mean():.3f}')\n",
        "    CalcValLossAndAccuracy(model, loss_fn, val_loader)"
      ],
      "metadata": {
        "id": "_vuXQq-LyGB2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "CkTIogdMyNKT",
        "outputId": "7e5569b9-dd9c-4cab-9ec4-e044c9598444",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "EPOCHS  = 10\n",
        "LR      = 1e-2\n",
        "OPT     = Adam(lstm_classifier.parameters(), lr=LR)\n",
        "LOSS_FN = nn.CrossEntropyLoss()\n",
        "\n",
        "TrainModel(model=lstm_classifier, loss_fn=LOSS_FN, optimizer=OPT, train_loader=train_loader, val_loader=val_loader, device=device, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "aZmjaQ8nyQQD",
        "outputId": "733ab81c-904c-4ecb-d9a7-1c3467a8ec6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:22<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.578\n",
            "Valid Loss: 1.552\n",
            "Valid Acc : 0.262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:22<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.535\n",
            "Valid Loss: 1.499\n",
            "Valid Acc : 0.316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:22<00:00,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.456\n",
            "Valid Loss: 1.435\n",
            "Valid Acc : 0.346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:22<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.297\n",
            "Valid Loss: 1.334\n",
            "Valid Acc : 0.394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:22<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.168\n",
            "Valid Loss: 1.294\n",
            "Valid Acc : 0.430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:25<00:00,  1.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.060\n",
            "Valid Loss: 1.328\n",
            "Valid Acc : 0.474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:27<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.949\n",
            "Valid Loss: 1.341\n",
            "Valid Acc : 0.523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:22<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.741\n",
            "Valid Loss: 1.151\n",
            "Valid Acc : 0.589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:27<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.560\n",
            "Valid Loss: 1.162\n",
            "Valid Acc : 0.607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:26<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.430\n",
            "Valid Loss: 1.202\n",
            "Valid Acc : 0.619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prompt_toolkit import output\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "EMBED_LEN  = 50\n",
        "HIDDEN_DIM = 75\n",
        "N_LAYERS   = 1\n",
        "\n",
        "target_classes = train_raw_data['Sentiment'].unique()\n",
        "\n",
        "class LSTMClassifier2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTMClassifier2, self).__init__()\n",
        "    self.emb_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=EMBED_LEN)\n",
        "    self.lstm = nn.LSTM(input_size=EMBED_LEN, hidden_size=HIDDEN_DIM, num_layers=N_LAYERS, batch_first=True, bidirectional=True)\n",
        "    self.fc = nn.Linear(in_features=HIDDEN_DIM*2, out_features=len(target_classes))\n",
        "    # self.drop = nn.Dropout(p=0.5)\n",
        "    \n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    emb = self.emb_layer(X_batch)\n",
        "    output, (h, c) = self.lstm(emb)\n",
        "    # output = self.drop(output)\n",
        "    return self.fc(output[:, -1])\n",
        "\n",
        "\n",
        "lstm_classifier2 = LSTMClassifier2()\n",
        "\n",
        "EPOCHS  = 10\n",
        "LR      = 1e-2\n",
        "OPT     = Adam(lstm_classifier2.parameters(), lr=LR)\n",
        "LOSS_FN = nn.CrossEntropyLoss()\n",
        "\n",
        "TrainModel(model=lstm_classifier2, loss_fn=LOSS_FN, optimizer=OPT, train_loader=train_loader, val_loader=val_loader, device=device, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "KJvd1IRR2gVB",
        "outputId": "6397d73f-8de6-42b0-d575-f7d3519f77ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:47<00:00,  1.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.580\n",
            "Valid Loss: 1.570\n",
            "Valid Acc : 0.278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:49<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.555\n",
            "Valid Loss: 1.523\n",
            "Valid Acc : 0.308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:44<00:00,  1.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.458\n",
            "Valid Loss: 1.442\n",
            "Valid Acc : 0.359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:43<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.289\n",
            "Valid Loss: 1.366\n",
            "Valid Acc : 0.426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:45<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.139\n",
            "Valid Loss: 1.275\n",
            "Valid Acc : 0.494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:44<00:00,  1.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.997\n",
            "Valid Loss: 1.248\n",
            "Valid Acc : 0.529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:43<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.811\n",
            "Valid Loss: 1.046\n",
            "Valid Acc : 0.607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:44<00:00,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.588\n",
            "Valid Loss: 0.959\n",
            "Valid Acc : 0.662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:44<00:00,  1.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.436\n",
            "Valid Loss: 1.051\n",
            "Valid Acc : 0.661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:42<00:00,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.340\n",
            "Valid Loss: 0.937\n",
            "Valid Acc : 0.678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prompt_toolkit import output\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "EMBED_LEN  = 50\n",
        "HIDDEN_DIM = 75\n",
        "N_LAYERS   = 1\n",
        "\n",
        "target_classes = train_raw_data['Sentiment'].unique()\n",
        "\n",
        "class LSTMClassifier3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTMClassifier3, self).__init__()\n",
        "    self.emb_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=EMBED_LEN)\n",
        "    self.lstm = nn.LSTM(input_size=EMBED_LEN, hidden_size=HIDDEN_DIM, num_layers=N_LAYERS, batch_first=True)\n",
        "    self.fc = nn.Linear(in_features=HIDDEN_DIM, out_features=len(target_classes))\n",
        "    self.drop = nn.Dropout(p=0.4)\n",
        "    \n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    emb = self.emb_layer(X_batch)\n",
        "    output, (h, c) = self.lstm(emb)\n",
        "    output = self.drop(output)\n",
        "    return self.fc(output[:, -1])\n",
        "\n",
        "\n",
        "lstm_classifier3 = LSTMClassifier3()\n",
        "\n",
        "EPOCHS  = 10\n",
        "LR      = 1e-2\n",
        "OPT     = Adam(lstm_classifier3.parameters(), lr=LR)\n",
        "LOSS_FN = nn.CrossEntropyLoss()\n",
        "\n",
        "TrainModel(model=lstm_classifier3, loss_fn=LOSS_FN, optimizer=OPT, train_loader=train_loader, val_loader=val_loader, device=device, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "qr1bGIwK3lMX",
        "outputId": "8d56001f-2604-453f-cd80-208c9511db4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:20<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.582\n",
            "Valid Loss: 1.559\n",
            "Valid Acc : 0.278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:21<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.575\n",
            "Valid Loss: 1.575\n",
            "Valid Acc : 0.279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:22<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.558\n",
            "Valid Loss: 1.556\n",
            "Valid Acc : 0.293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:21<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.504\n",
            "Valid Loss: 1.448\n",
            "Valid Acc : 0.328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:21<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.367\n",
            "Valid Loss: 1.336\n",
            "Valid Acc : 0.380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:21<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.212\n",
            "Valid Loss: 1.282\n",
            "Valid Acc : 0.466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:20<00:00,  1.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.069\n",
            "Valid Loss: 1.225\n",
            "Valid Acc : 0.526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:21<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.826\n",
            "Valid Loss: 1.066\n",
            "Valid Acc : 0.595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:21<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.609\n",
            "Valid Loss: 1.065\n",
            "Valid Acc : 0.657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:22<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.461\n",
            "Valid Loss: 0.960\n",
            "Valid Acc : 0.659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prompt_toolkit import output\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "EMBED_LEN  = 50\n",
        "HIDDEN_DIM = 256\n",
        "N_LAYERS   = 1\n",
        "\n",
        "target_classes = train_raw_data['Sentiment'].unique()\n",
        "\n",
        "class LSTMClassifier4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTMClassifier4, self).__init__()\n",
        "    self.emb_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=EMBED_LEN)\n",
        "    self.lstm = nn.LSTM(input_size=EMBED_LEN, hidden_size=HIDDEN_DIM, num_layers=N_LAYERS, batch_first=True)\n",
        "    self.fc = nn.Linear(in_features=HIDDEN_DIM, out_features=len(target_classes))\n",
        "    self.drop = nn.Dropout(p=0.4)\n",
        "    \n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    emb = self.emb_layer(X_batch)\n",
        "    output, (h, c) = self.lstm(emb)\n",
        "    output = self.drop(output)\n",
        "    return self.fc(output[:, -1])\n",
        "\n",
        "\n",
        "lstm_classifier4 = LSTMClassifier4()\n",
        "\n",
        "EPOCHS  = 10\n",
        "LR      = 1e-2\n",
        "OPT     = Adam(lstm_classifier4.parameters(), lr=LR)\n",
        "LOSS_FN = nn.CrossEntropyLoss()\n",
        "\n",
        "TrainModel(model=lstm_classifier4, loss_fn=LOSS_FN, optimizer=OPT, train_loader=train_loader, val_loader=val_loader, device=device, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "mWdXI1sF4AFr",
        "outputId": "19128749-af28-4212-d660-eac31f48b2f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:43<00:00,  3.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.627\n",
            "Valid Loss: 1.569\n",
            "Valid Acc : 0.265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:45<00:00,  3.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.576\n",
            "Valid Loss: 1.563\n",
            "Valid Acc : 0.279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:55<00:00,  3.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.563\n",
            "Valid Loss: 1.537\n",
            "Valid Acc : 0.287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 28/33 [01:32<00:16,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-4cdebaa6a697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mLOSS_FN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_classifier4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS_FN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-6292efbaa7ca>\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(model, loss_fn, optimizer, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0mY_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-4cdebaa6a697>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X_batch)\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    775\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prompt_toolkit import output\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "EMBED_LEN  = 50\n",
        "HIDDEN_DIM = 75\n",
        "N_LAYERS   = 1\n",
        "\n",
        "target_classes = train_raw_data['Sentiment'].unique()\n",
        "\n",
        "class LSTMClassifier5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTMClassifier5, self).__init__()\n",
        "    self.emb_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=EMBED_LEN)\n",
        "    self.lstm = nn.LSTM(input_size=EMBED_LEN, hidden_size=HIDDEN_DIM, num_layers=N_LAYERS, batch_first=True, bidirectional=True)\n",
        "    self.fc = nn.Linear(in_features=HIDDEN_DIM*2, out_features=len(target_classes))\n",
        "    self.drop = nn.Dropout(p=0.4)\n",
        "    \n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    emb = self.emb_layer(X_batch)\n",
        "    output, (h, c) = self.lstm(emb)\n",
        "    output = self.drop(output)\n",
        "    return self.fc(output[:, -1])\n",
        "\n",
        "\n",
        "lstm_classifier5 = LSTMClassifier5()\n",
        "\n",
        "EPOCHS  = 15\n",
        "LR      = 1e-2\n",
        "OPT     = Adam(lstm_classifier5.parameters(), lr=LR)\n",
        "LOSS_FN = nn.CrossEntropyLoss()\n",
        "\n",
        "TrainModel(model=lstm_classifier5, loss_fn=LOSS_FN, optimizer=OPT, train_loader=train_loader, val_loader=val_loader, device=device, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "2SE1q_Tb4XyA",
        "outputId": "85729f45-8f8e-401d-8dc4-0b61e8b25858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:48<00:00,  1.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.582\n",
            "Valid Loss: 1.559\n",
            "Valid Acc : 0.278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:47<00:00,  1.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.574\n",
            "Valid Loss: 1.602\n",
            "Valid Acc : 0.279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:47<00:00,  1.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.572\n",
            "Valid Loss: 1.559\n",
            "Valid Acc : 0.278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:47<00:00,  1.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.531\n",
            "Valid Loss: 1.586\n",
            "Valid Acc : 0.295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:46<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.441\n",
            "Valid Loss: 1.442\n",
            "Valid Acc : 0.346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:45<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.276\n",
            "Valid Loss: 1.308\n",
            "Valid Acc : 0.409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.141\n",
            "Valid Loss: 1.360\n",
            "Valid Acc : 0.432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:45<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.037\n",
            "Valid Loss: 1.346\n",
            "Valid Acc : 0.457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:46<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.929\n",
            "Valid Loss: 1.301\n",
            "Valid Acc : 0.501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:47<00:00,  1.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.767\n",
            "Valid Loss: 1.366\n",
            "Valid Acc : 0.546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:46<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.614\n",
            "Valid Loss: 1.485\n",
            "Valid Acc : 0.575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:46<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.461\n",
            "Valid Loss: 1.254\n",
            "Valid Acc : 0.600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:46<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.352\n",
            "Valid Loss: 1.292\n",
            "Valid Acc : 0.610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:47<00:00,  1.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.289\n",
            "Valid Loss: 1.480\n",
            "Valid Acc : 0.622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:49<00:00,  1.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.249\n",
            "Valid Loss: 1.329\n",
            "Valid Acc : 0.617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MakePredictions(model, loader, device):\n",
        "  Y_shuffled, Y_preds= [], []\n",
        "  for X, Y in loader:\n",
        "    X.to(device)\n",
        "    Y.to(device)\n",
        "    preds = model(X)\n",
        "    Y_preds.append(preds)\n",
        "    Y_shuffled.append(Y)\n",
        "  gc.collect()\n",
        "  Y_preds, Y_shuffled = torch.cat(Y_preds), torch.cat(Y_shuffled)\n",
        "\n",
        "  return Y_shuffled.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1)\n",
        "\n",
        "Y_actual, Y_preds = MakePredictions(lstm_classifier, test_loader, device)"
      ],
      "metadata": {
        "id": "vV90qzu0yWPh"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "target_classes = le.inverse_transform(target_classes)\n",
        "print(f'Test Accuracy: {accuracy_score(Y_actual, Y_preds)}')\n",
        "print('\\nClassification report: ')\n",
        "print(classification_report(Y_actual, Y_preds, target_names=target_classes))\n",
        "print('\\nConfusion Matrix: ')\n",
        "print(confusion_matrix(Y_actual, Y_preds))"
      ],
      "metadata": {
        "id": "g7qaz0AiIUdd",
        "outputId": "0f147f22-7951-46a8-b589-daeb8df0c7f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6967930029154519\n",
            "\n",
            "Classification report: \n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "           Neutral       0.74      0.63      0.68       548\n",
            "          Positive       0.76      0.74      0.75       662\n",
            "Extremely Negative       0.61      0.65      0.63       992\n",
            "          Negative       0.84      0.70      0.76       771\n",
            "Extremely Positive       0.65      0.74      0.69      1143\n",
            "\n",
            "          accuracy                           0.70      4116\n",
            "         macro avg       0.72      0.69      0.70      4116\n",
            "      weighted avg       0.71      0.70      0.70      4116\n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            "[[346   6 182   2  12]\n",
            " [  3 487   7   0 165]\n",
            " [104  18 649  45 176]\n",
            " [  6  11 111 540 103]\n",
            " [ 10 120 112  55 846]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2"
      ],
      "metadata": {
        "id": "fCJJVARHxQ3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader\n",
        "\n",
        "pretrained_embeddings = gensim.downloader.load('fasttext-wiki-news-subwords-300')"
      ],
      "metadata": {
        "id": "DQg3IWnlIZIf",
        "outputId": "88bf9f98-ff23-49ae-b882-ca705707b319",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.7% 955.4/958.4MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_vectors = torch.tensor(pretrained_embeddings.vectors)"
      ],
      "metadata": {
        "id": "Xd9gr78wIbcV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_LEN  = 300\n",
        "HIDDEN_DIM = 75\n",
        "N_LAYERS   = 1\n",
        "\n",
        "target_classes = train_raw_data['Sentiment'].unique()\n",
        "\n",
        "class LSTMClassifier2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTMClassifier2, self).__init__()\n",
        "    self.emb_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=EMBED_LEN)\n",
        "    self.lstm = nn.LSTM(input_size=EMBED_LEN, hidden_size=HIDDEN_DIM, num_layers=N_LAYERS, batch_first=True)\n",
        "    self.fc = nn.Linear(in_features=HIDDEN_DIM, out_features=len(target_classes))\n",
        "    self.drop = nn.Dropout(p=0.5)\n",
        "    self.init_embeds()\n",
        "\n",
        "  def init_embeds(self):\n",
        "    weights = pretrained_vectors\n",
        "    self.emb_layer = nn.Embedding.from_pretrained(weights, freeze=False)\n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    emb = self.emb_layer(X_batch)\n",
        "    output, (h, c) = self.lstm(emb)\n",
        "    # output = self.drop(output)\n",
        "    return self.drop(self.fc(output[:, -1]))"
      ],
      "metadata": {
        "id": "J3uUJuovIdf_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_classifier2 = LSTMClassifier2()\n",
        "lstm_classifier2"
      ],
      "metadata": {
        "id": "E14DtcJbIjja",
        "outputId": "7f2875e5-402b-452c-cd96-9983b8bd9c90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMClassifier2(\n",
              "  (emb_layer): Embedding(999999, 300)\n",
              "  (lstm): LSTM(300, 75, batch_first=True)\n",
              "  (fc): Linear(in_features=75, out_features=5, bias=True)\n",
              "  (drop): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS  = 10\n",
        "LR      = 1e-3\n",
        "OPT     = Adam(lstm_classifier2.parameters(), lr=LR)\n",
        "LOSS_FN = nn.CrossEntropyLoss()\n",
        "\n",
        "TrainModel(model=lstm_classifier2, loss_fn=LOSS_FN, optimizer=OPT, train_loader=train_loader, val_loader=val_loader, device=device, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "icRX7E5YIoeF",
        "outputId": "19706007-a7c4-4547-9f5b-acc38e1a94e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [03:07<00:00,  5.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.593\n",
            "Valid Loss: 1.573\n",
            "Valid Acc : 0.243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [03:05<00:00,  5.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.591\n",
            "Valid Loss: 1.584\n",
            "Valid Acc : 0.246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [03:13<00:00,  5.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.586\n",
            "Valid Loss: 1.587\n",
            "Valid Acc : 0.246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/33 [00:05<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-85e6f7201a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mLOSS_FN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_classifier2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS_FN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-6292efbaa7ca>\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(model, loss_fn, optimizer, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS  = 10\n",
        "LR      = 1e-2\n",
        "OPT     = Adam(lstm_classifier2.parameters(), lr=LR)\n",
        "LOSS_FN = nn.NLLLoss(reduction='sum')\n",
        "\n",
        "TrainModel(model=lstm_classifier2, loss_fn=LOSS_FN, optimizer=OPT, train_loader=train_loader, val_loader=val_loader, device=device, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "NFZ1l8totMTw",
        "outputId": "80299103-9465-407f-efe7-a30dea0e6143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:47<00:00,  1.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: -104925.234\n",
            "Valid Loss: -86003.016\n",
            "Valid Acc : 0.561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:45<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: -127157.031\n",
            "Valid Loss: -102956.828\n",
            "Valid Acc : 0.580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 5/33 [00:07<00:41,  1.48s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-8a1dccd52f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mLOSS_FN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_classifier2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS_FN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-104-6292efbaa7ca>\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(model, loss_fn, optimizer, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    277\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mforeach\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                                 \u001b[0mper_device_and_dtype_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "EMBED_LEN  = 50\n",
        "HIDDEN_DIM = 75\n",
        "N_LAYERS   = 1\n",
        "\n",
        "\n",
        "class LSTMClassifier3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTMClassifier3, self).__init__()\n",
        "    self.emb_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=EMBED_LEN)\n",
        "    self.lstm = nn.LSTM(input_size=EMBED_LEN, hidden_size=HIDDEN_DIM, num_layers=N_LAYERS, batch_first=True)\n",
        "    self.fc = nn.Linear(in_features=HIDDEN_DIM, out_features=len(target_classes))\n",
        "    # self.drop = nn.Dropout(p=0.2)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    self.hidden = self.init_hidden()\n",
        "\n",
        "  def init_hidden(self):\n",
        "    h0 = Variable(torch.zeros(N_LAYERS, 1024, HIDDEN_DIM))\n",
        "    c0 = Variable(torch.zeros(N_LAYERS, 1024, HIDDEN_DIM))\n",
        "    hidden = (h0, c0)\n",
        "    return hidden\n",
        "\n",
        "  def forward(self, X_batch, hidden):\n",
        "    # self.hidden = self.init_hidden(X_batch.shape[0])\n",
        "    emb = self.emb_layer(X_batch)\n",
        "    output, self.hidden = self.lstm(emb, self.hidden)\n",
        "    output = output[:,-1,:]\n",
        "    output = self.fc(output)\n",
        "    output = self.softmax(output)\n",
        "    return output, self.hidden"
      ],
      "metadata": {
        "id": "Zxa_1UrKWf4a"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_classifier3 = LSTMClassifier3()\n",
        "lstm_classifier3"
      ],
      "metadata": {
        "id": "3UEraOghX80N",
        "outputId": "1c6e396b-c6c3-458b-f691-b2137488cc11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMClassifier3(\n",
              "  (emb_layer): Embedding(50615, 50)\n",
              "  (lstm): LSTM(50, 75, batch_first=True)\n",
              "  (fc): Linear(in_features=75, out_features=5, bias=True)\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS  = 10\n",
        "LR      = 1e-2\n",
        "OPT     = Adam(lstm_classifier3.parameters(), lr=LR)\n",
        "LOSS_FN = nn.CrossEntropyLoss()\n",
        "\n",
        "TrainModel(model=lstm_classifier3, loss_fn=LOSS_FN, optimizer=OPT, train_loader=train_loader, val_loader=val_loader, device=device, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "Y-2beXW8NX75",
        "outputId": "ca1f4a10-d33a-4c48-8d7d-2fd051e087ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/33 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-8c945299f4fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mLOSS_FN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_classifier3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS_FN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-104-6292efbaa7ca>\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(model, loss_fn, optimizer, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0mY_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'hidden'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "EMBED_LEN  = 50\n",
        "HIDDEN_DIM = 75\n",
        "N_LAYERS   = 1\n",
        "\n",
        "\n",
        "class LSTMClassifier4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTMClassifier4, self).__init__()\n",
        "    self.emb_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=EMBED_LEN)\n",
        "    self.lstm = nn.LSTM(input_size=EMBED_LEN, hidden_size=HIDDEN_DIM, num_layers=N_LAYERS, batch_first=True, bidirectional=True)\n",
        "    self.fc1 = nn.Linear(in_features=HIDDEN_DIM*2, out_features=HIDDEN_DIM)\n",
        "    self.fc2 = nn.Linear(in_features=HIDDEN_DIM, out_features=len(target_classes))\n",
        "    self.drop = nn.Dropout(p=0.2)\n",
        "    # self.init_embeds()\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    h0 = Variable(torch.zeros(N_LAYERS*2, batch_size, HIDDEN_DIM))\n",
        "    c0 = Variable(torch.zeros(N_LAYERS*2, batch_size, HIDDEN_DIM))\n",
        "    return h0, c0\n",
        "\n",
        "  def forward(self, X_batch):\n",
        "    self.hidden = self.init_hidden(X_batch.shape[0])\n",
        "    emb = self.emb_layer(X_batch)\n",
        "    output, self.hidden = self.lstm(emb, self.hidden)\n",
        "    output = self.fc1(output)\n",
        "    output = self.drop(self.fc2(output[:, -1]))\n",
        "    return output"
      ],
      "metadata": {
        "id": "hF9-BDOHbyUd"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_classifier4 = LSTMClassifier4()\n",
        "lstm_classifier4"
      ],
      "metadata": {
        "id": "aPpfeuuGdi8Z",
        "outputId": "80ab7860-8d7c-474e-9d20-92d521e2ab16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMClassifier4(\n",
              "  (emb_layer): Embedding(50615, 50)\n",
              "  (lstm): LSTM(50, 75, batch_first=True, bidirectional=True)\n",
              "  (fc1): Linear(in_features=150, out_features=75, bias=True)\n",
              "  (fc2): Linear(in_features=75, out_features=5, bias=True)\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS  = 10\n",
        "LR      = 1e-2\n",
        "OPT     = Adam(lstm_classifier4.parameters(), lr=LR)\n",
        "LOSS_FN = nn.CrossEntropyLoss()\n",
        "\n",
        "TrainModel(model=lstm_classifier4, loss_fn=LOSS_FN, optimizer=OPT, train_loader=train_loader, val_loader=val_loader, device=device, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "R2fQTg9bYUFG",
        "outputId": "2f3f3ba9-0817-443c-bb52-426c94886b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:23<00:00,  2.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.588\n",
            "Valid Loss: 1.586\n",
            "Valid Acc : 0.269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:22<00:00,  2.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.582\n",
            "Valid Loss: 1.574\n",
            "Valid Acc : 0.270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:20<00:00,  2.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.580\n",
            "Valid Loss: 1.570\n",
            "Valid Acc : 0.261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 21/33 [00:55<00:31,  2.65s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-4a58b047fdd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mLOSS_FN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_classifier4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS_FN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-6292efbaa7ca>\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(model, loss_fn, optimizer, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = vocab.vectors"
      ],
      "metadata": {
        "id": "KhRfmZMydfps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O5Aig4gfgsAp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}